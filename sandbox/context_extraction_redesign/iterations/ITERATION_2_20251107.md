# Iteration 2 - November 7, 2025 (10:58)

**File:** `test_results_20251107_105802.json`

## Comparison with Baseline

| Metric | Baseline | Iteration 2 | Change |
|--------|----------|-------------|--------|
| **Tests Passed** | 2/10 (20%) | 4/10 (40%) | +100% ✅ |
| **Average Accuracy** | 42.9% | 61.2% | +18.3% ✅ |
| **Simple Tests** | 92.9% | 92.9% | No change |
| **Medium Tests** | 42.9% | 100.0% | +57.1% ✅✅ |
| **Complex Tests** | 28.6% | 46.7% | +18.1% ✅ |

## Key Improvements

### Tests That Now Pass ✅
1. **Test 2: The Sentence That Broke Us** - 28.6% → 71.4% (PASS!)
2. **Test 6: Positive Assessment** - 42.9% → 100.0% (PASS!)

### Significant Accuracy Gains
- Test 2: +42.8 percentage points
- Test 3: +8.1 pp
- Test 5: +28.5 pp
- Test 6: +57.1 pp (now perfect!)

### What Worked

**1. Naming Convention Rules**
- Added explicit rule: "Use underscores in domain/role names"
- Result: Better consistency in domain/role naming

**2. Minimalist Extraction**
- Rule: "Extract the MINIMUM number of entities needed"
- Result: Test 6 now creates exactly 1 assessment (was creating 2)
- Perfect 100% accuracy on medium test

**3. Concrete Examples**
- Added 3 detailed examples in prompt
- Showed exact expected output format
- Result: Better alignment with expected structure

**4. Clear Entity Guidelines**
- Separated guidelines by entity type
- Explicit rules for each field
- Result: More consistent extraction

## Remaining Issues

### Still Struggling (< 50% accuracy)

**Test 7: Ambiguous Reference (14.3%)**
- Issue: "unknown output" vs "it" - ambiguity handling
- Challenge: How to handle pronouns without context

**Test 8: Multiple Systems (40.0%)**
- Issue: Complex system dependencies
- Missing proper data flow modeling

**Test 10: Comparative Assessment (42.9%)**
- Issue: "data engineering" (team name) vs "data engineer" (person)
- Temporal comparisons not well handled

### Moderate Performance (50-70%)

**Test 3: Multi-Output Dependency Chain (43.8%)**
- Cascading dependencies still challenging
- Multiple outputs with causal chains

**Test 4: Team + Process + System (42.9%)**
- Output name mismatch: "project visibility" vs "visibility"
- Root cause component: process_maturity vs team_execution

**Test 5: Implicit Assessment with Symptom (57.1%)**
- Output name: "production monitoring" vs "monitoring"
- Minor naming variations

## Changes Made to Prompt

### Added
1. **CRITICAL RULES section** - 5 key principles
2. **Entity-specific guidelines** - Detailed rules per entity type
3. **Concrete examples** - 3 full extraction examples
4. **Underscore convention** - Explicit naming rules
5. **Minimalist approach** - "Only extract what is clearly present"

### Emphasized
- ONE assessment per target (not multiple)
- Exact name matching from user input
- Clear causal relationships only
- Brief, precise descriptions

## Next Steps

### High Priority
1. **Handle ambiguous references better**
   - Add rules for pronouns ("it", "they", "that")
   - When to use "unknown" vs literal text

2. **Improve output naming consistency**
   - "production monitoring" vs "monitoring"
   - "project visibility" vs "visibility"
   - Add rules about when to include qualifiers

3. **Better team vs person distinction**
   - "data engineering" (team) vs "data engineer" (person)
   - Clarify when to use singular vs plural

### Medium Priority
4. **Complex dependency chains**
   - Multi-hop dependencies
   - Cascading effects
   - Better examples needed

5. **Root cause component selection**
   - When process_maturity vs team_execution
   - Clearer decision rules

## Configuration

- **Model:** gemini-2.5-flash
- **Temperature:** 0.1
- **Max Tokens:** 4096
- **Prompt Length:** ~3000 characters (increased from ~800)

## Cost

~$0.0004 per run (same as baseline)

## Conclusion

**Significant improvement: +18.3% average accuracy, doubled pass rate (2→4 tests).**

The detailed prompt with examples and rules helped a lot, especially for:
- Medium complexity cases (now 100%)
- Preventing over-extraction
- Better naming conventions

Still need work on:
- Ambiguous references
- Complex multi-entity scenarios
- Subtle naming variations
