# Baseline Run - November 7, 2025

**File:** `test_results_20251107_105309.json`

## Summary

- **Total Tests:** 10
- **Passed:** 2 (20%)
- **Failed:** 8 (80%)
- **Average Accuracy:** 42.9%

## By Difficulty

| Difficulty | Passed | Avg Accuracy |
|------------|--------|--------------|
| Simple | 2/2 | 92.9% ✅ |
| Medium | 0/1 | 42.9% |
| Complex | 0/7 | 28.6% ❌ |

## Individual Test Results

| ID | Test Name | Difficulty | Accuracy | Status |
|----|-----------|------------|----------|--------|
| 1 | Simple Assessment | Simple | 85.7% | ✅ PASS |
| 2 | The Sentence That Broke Us | Complex | 28.6% | ❌ FAIL |
| 3 | Multi-Output Dependency Chain | Complex | 35.7% | ❌ FAIL |
| 4 | Team + Process + System | Complex | 7.1% | ❌ FAIL |
| 5 | Implicit Assessment with Symptom | Complex | 28.6% | ❌ FAIL |
| 6 | Positive Assessment | Medium | 42.9% | ❌ FAIL |
| 7 | Ambiguous Reference | Complex | 14.3% | ❌ FAIL |
| 8 | Multiple Systems | Complex | 33.3% | ❌ FAIL |
| 9 | Partial Information | Simple | 100.0% | ✅ PASS |
| 10 | Comparative Assessment | Complex | 52.4% | ❌ FAIL |

## Key Issues Identified

### 1. Naming Convention Mismatches
- Expected: `customer_support` (underscore)
- Got: `customer support` (space)
- **Impact:** Causes exact match failures

### 2. Over-Extraction
- Gemini sometimes creates multiple entities when one expected
- Example: Test 6 created 2 assessments instead of 1
- **Impact:** Reduces precision scores

### 3. Semantic Variations
- Team names: "data engineering" vs "data engineer"
- Descriptions vary in wording but capture same meaning
- **Impact:** Fails exact match but semantically correct

### 4. Complex Dependency Chains
- Struggles with multi-hop dependencies
- Test 3 (cascading outputs) only 35.7% accurate
- **Impact:** Core use case not working well

## Next Steps for Improvement

### High Priority
1. **Add naming convention rules** to prompt
   - Specify underscore vs space conventions
   - Provide examples of correct entity names

2. **Clarify extraction boundaries**
   - When to extract one vs multiple entities
   - What constitutes a separate assessment vs part of existing one

3. **Improve dependency extraction**
   - Better examples of dependency chains
   - Clearer rules for causal relationships

### Medium Priority
4. **Semantic matching tolerance**
   - Consider fuzzy matching for entity names
   - Allow description variations if semantically equivalent

5. **Test case refinement**
   - Review if expected outputs are too strict
   - Adjust for reasonable Gemini interpretations

## Configuration

- **Model:** gemini-2.5-flash
- **Temperature:** 0.1 (low for structured extraction)
- **Max Tokens:** 4096
- **Cost:** ~$0.0004 per run

## Notes

Simple cases work well (92.9% avg). Complex multi-entity scenarios need significant prompt engineering to improve from 28.6% baseline.
